{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b0e8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27081861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, D_in, D_out, activation_type=\"relu\"):\n",
    "        self.D_in = D_in\n",
    "        self.D_out = D_out\n",
    "        self.activation_type = activation_type\n",
    "        \n",
    "        self.W = torch.randn((D_in, D_out)) * torch.sqrt(torch.tensor(2.0 / D_in))\n",
    "        self.b = torch.zeros(D_out)\n",
    "        self.W.requires_grad = True\n",
    "        self.b.requires_grad = True\n",
    "        \n",
    "        if activation_type == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation_type == \"tanh\":\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation_type == \"sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else:\n",
    "            self.activation = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        z = X @ self.W + self.b\n",
    "        if self.activation is not None:\n",
    "            a = self.activation(z)\n",
    "        else:\n",
    "            a = z\n",
    "        return a, z\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "928431f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layer_dims, activation_types=None, optimizer_type=None):\n",
    "        self.layers = []\n",
    "        self.layer_dims = layer_dims\n",
    "        self.optimizer_type = optimizer_type\n",
    "        \n",
    "        if activation_types is None:\n",
    "            activation_types = [\"relu\"] * (len(layer_dims) - 2) + [\"none\"]\n",
    "\n",
    "        for i in range(len(layer_dims) - 1):\n",
    "            layer = Layer(layer_dims[i], layer_dims[i+1], activation_types[i])\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        if optimizer_type is not None and optimizer_type == \"Adam\":\n",
    "            self.mt = [torch.zeros_like(p,requires_grad=False) for p in self.parameters()]\n",
    "            self.vt = [torch.zeros_like(p,requires_grad=False) for p in self.parameters()]\n",
    "            self.t = 0\n",
    "        elif optimizer_type is not None and optimizer_type == \"SGD\":\n",
    "            self.velocity = [torch.zeros_like(p,requires_grad=False) for p in self.parameters()]\n",
    "\n",
    "    def forward(self, X):\n",
    "        a = X\n",
    "        for layer in self.layers:\n",
    "            a, _ = layer.forward(a)\n",
    "        return a\n",
    "\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params.extend(layer.parameters())\n",
    "        return params\n",
    "\n",
    "    def train_epoch(self, X, y, learning_rate, momentum=0.9):\n",
    "        predictions = self.forward(X)\n",
    "        loss = torch.mean((predictions - y) ** 2)\n",
    "        loss.backward()\n",
    "\n",
    "        if self.optimizer_type is None:\n",
    "            with torch.no_grad():\n",
    "                for param in self.parameters():\n",
    "                    param -= learning_rate * param.grad\n",
    "                    \n",
    "        elif self.optimizer_type == \"SGD\":\n",
    "            with torch.no_grad():\n",
    "                for i, param in enumerate(self.parameters()):\n",
    "                    self.velocity[i] = momentum * self.velocity[i] - learning_rate * param.grad\n",
    "                    param += self.velocity[i]\n",
    "                    \n",
    "        elif self.optimizer_type == \"Adam\":\n",
    "            beta1 = 0.9 \n",
    "            beta2 = 0.999\n",
    "            epsilon = 1e-8\n",
    "            self.t += 1  \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, param in enumerate(self.parameters()):\n",
    "                    self.mt[i] = beta1 * self.mt[i] + (1 - beta1) * param.grad\n",
    "                    self.vt[i] = beta2 * self.vt[i] + (1 - beta2) * (param.grad ** 2)\n",
    "                    mt_hat = self.mt[i] / (1 - beta1 ** self.t)\n",
    "                    vt_hat = self.vt[i] / (1 - beta2 ** self.t)\n",
    "                    param -= learning_rate * mt_hat / (torch.sqrt(vt_hat + epsilon))\n",
    "\n",
    "        for param in self.parameters():\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()\n",
    "\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "269c9e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,)) \n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "images,labels = next(iter(train_loader))\n",
    "# images.shape,labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2cd59b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: Loss = 0.063990\n",
      "Epoch 2/3: Loss = 0.031553\n",
      "Epoch 3/3: Loss = 0.022946\n"
     ]
    }
   ],
   "source": [
    "layer_dims = [784, 128, 64, 32, 10]\n",
    "activation_types = [\"relu\", \"relu\", \"relu\", \"none\"]\n",
    "optimizer_type = \"SGD\"\n",
    "model = Network(layer_dims, activation_types,optimizer_type)\n",
    "\n",
    "def train_mnist_epoch(model, train_loader, learning_rate):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.reshape(-1, 28 * 28)\n",
    "        \n",
    "        labels_one_hot = torch.zeros(labels.shape[0], 10)\n",
    "        labels_one_hot.scatter_(1, labels.unsqueeze(1), 1)\n",
    "        \n",
    "        loss = model.train_epoch(images, labels_one_hot, learning_rate)\n",
    "        total_loss += loss\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 3\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = train_mnist_epoch(model, train_loader, learning_rate)\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: Loss = {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dccad6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.2300033569336\n"
     ]
    }
   ],
   "source": [
    "total_test = 0\n",
    "correct_prediction = 0\n",
    "\n",
    "for images,labels in test_loader:\n",
    "    images = images.reshape(-1,28*28)\n",
    "    prediction = model.forward(images)\n",
    "    prediction = torch.argmax(prediction,dim =1)\n",
    "    correct_prediction += torch.sum(prediction == labels)\n",
    "    total_test += labels.shape[0]\n",
    "accuracy = correct_prediction/total_test *100\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
